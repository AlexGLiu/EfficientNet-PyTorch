{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwishImplementation(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class MemoryEfficientSwish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return SwishImplementation.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_depth(inputs, skip_probability, training):\n",
    "    if not training: return inputs\n",
    "    batch_size = inputs.shape[0]\n",
    "    keep_prob = 1 - skip_probability\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device)\n",
    "    binary_tensor = torch.floor(random_tensor)\n",
    "    output = inputs / keep_prob * binary_tensor\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, channel, se_ratio, activation = None):\n",
    "        super().__init__()\n",
    "        self.squeezed_channel = max(1, int(channel * se_ratio))\n",
    "        self.se_reduce = nn.Conv2d(channel, self.squeezed_channel, 1)\n",
    "        self.se_expand = nn.Conv2d(self.squeezed_channel, channel, 1)\n",
    "        self.activation = activation\n",
    "    def forward(self, x):\n",
    "        x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "        x_squeezed = self.se_expand(self.activation(self.se_reduce(x_squeezed)))\n",
    "        return torch.sigmoid(x_squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConvBasicBlc(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, expand_ratio, stride, kernel, \n",
    "                 se_ratio, skip_probability, bn_momentum, bn_epsilon):\n",
    "        super().__init__()\n",
    "        self.expand_option = (expand_ratio != 1)\n",
    "        med_channel = in_channel*expand_ratio\n",
    "        self.activation = MemoryEfficientSwish()\n",
    "        self.skip_probability = skip_probability\n",
    "        if self.expand_option:\n",
    "            self.expand = nn.Conv2d(in_channel, med_channel, 1)\n",
    "            self.bn_expand = nn.BatchNorm2d(num_features=med_channel, momentum=(1-bn_momentum),\n",
    "                                            eps=bn_epsilon)\n",
    "        self.depth_wise = nn.Conv2d(med_channel, med_channel, kernel, stride = stride, \n",
    "                                    padding=math.ceil((kernel-stride)/2), groups=med_channel)\n",
    "        self.bn_depth_wise = nn.BatchNorm2d(num_features=med_channel, momentum=(1-bn_momentum),\n",
    "                                            eps=bn_epsilon)\n",
    "        \n",
    "        if (se_ratio is not None) and (0 < se_ratio < 1):\n",
    "            self.se_operation = SqueezeExcitation(med_channel, se_ratio, self.activation)\n",
    "        else:\n",
    "            self.se_operation = None\n",
    "        self.real_out = nn.Conv2d(med_channel, out_channel, 1)\n",
    "        self.bn_out = nn.BatchNorm2d(num_features=out_channel, momentum=(1-bn_momentum),\n",
    "                                            eps=bn_epsilon)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        \n",
    "        if self.expand_option:\n",
    "            x = self.expand(x)\n",
    "            x = self.bn_expand(x)\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        x = self.depth_wise(x)\n",
    "        x = self.bn_depth_wise(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        if self.se_operation is not None:\n",
    "            x_squeezed = self.se_operation(x)\n",
    "            x = x_squeezed * x\n",
    "            \n",
    "        x = self.real_out(x)\n",
    "        x = self.bn_out(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        if x.shape == inputs.shape:\n",
    "            if self.skip_probability:\n",
    "                x = stochastic_depth(x, self.skip_probability, training=self.training)\n",
    "            x = x + inputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConvBlc(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, expand_ratio, stride, kernel, \n",
    "                 se_ratio, skip_probability, bn_momentum, bn_epsilon, n_repeat):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for i in range(n_repeat):\n",
    "            if i == 0:\n",
    "                self.blocks.append(MBConvBasicBlc(in_channel, out_channel, \n",
    "                                                  expand_ratio, stride, kernel, \n",
    "                                                  se_ratio, skip_probability,\n",
    "                                                  bn_momentum, bn_epsilon))\n",
    "            else:\n",
    "                self.blocks.append(MBConvBasicBlc(out_channel, out_channel, \n",
    "                                                  expand_ratio, 1, kernel, \n",
    "                                                  se_ratio, skip_probability,\n",
    "                                                  bn_momentum, bn_epsilon))\n",
    "    def forward(self, x):\n",
    "        for blc in self.blocks:\n",
    "            x = blc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, blocks_args=None):\n",
    "        super().__init__()\n",
    "#         assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "#         assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._blocks_args = blocks_args\n",
    "        \n",
    " #       Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - 0.99\n",
    "        bn_eps = 0.001\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = 32\n",
    "#         out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "#         self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._conv_stem = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, \n",
    "                                    padding=1)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "        \n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "            \n",
    "#             # Update block input and output filters based on depth multiplier.\n",
    "#             block_args = block_args._replace(\n",
    "#                 input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "#                 output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "#                 num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "#             )\n",
    "#             # build block with new bottleneck block function\n",
    "            self._blocks.append(MBConvBlc(**block_args))\n",
    "            \n",
    "        # Head\n",
    "#         in_channels = block_args.output_filters  # output of final block\n",
    "        in_channels = block_args['out_channel']\n",
    "        out_channels =1280 # round_filters(1280, self._global_params)\n",
    "        \n",
    "        # Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._conv_head = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        \n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self._dropout = nn.Dropout(0.2)\n",
    "        self._fc = nn.Linear(out_channels, 256)\n",
    "        \n",
    "        self.output = nn.Linear(256, 1)\n",
    "        \n",
    "        self._swish = MemoryEfficientSwish()\n",
    "        \n",
    "#     def set_swish(self, memory_efficient=True):\n",
    "#     \"\"\"Sets swish function as memory efficient (for training) or standard (for export)\"\"\"\n",
    "#         self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\n",
    "#         for block in self._blocks:\n",
    "#             block.set_swish(memory_efficient)\n",
    "    def forward(self, inputs):\n",
    "        bs = inputs.size(0)\n",
    "        #Stem\n",
    "        x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "#             drop_connect_rate = 0.2\n",
    "#             if drop_connect_rate:\n",
    "#                 drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x)\n",
    "\n",
    "        # Head\n",
    "        x = self._swish(self._bn1(self._conv_head(x)))\n",
    "        # Pooling and final linear layer\n",
    "        x = self._avg_pooling(x)\n",
    "        x = x.view(bs, -1)\n",
    "        x = self._dropout(x)\n",
    "        x = self._swish(self._fc(x))\n",
    "        \n",
    "        x = self._dropout(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b0 parameters\n",
    "mb_params = {'kernel':3,'n_repeat':1,'in_channel':32, 'out_channel':16,'expand_ratio':1,'stride':1, 'se_ratio':1/4,\n",
    "           'skip_probability':0.2,'bn_momentum':0.99, 'bn_epsilon':0.001}\n",
    "block_args=[mb_params]\n",
    "block_args.append({'kernel':3,'n_repeat':2,'in_channel':16, 'out_channel':24,'expand_ratio':6,'stride':2, 'se_ratio':1/4,\n",
    "           'skip_probability':0.2,'bn_momentum':0.99, 'bn_epsilon':0.001})\n",
    "block_args.append({'kernel':5,'n_repeat':2,'in_channel':24, 'out_channel':40,'expand_ratio':6,'stride':2, 'se_ratio':1/4,\n",
    "           'skip_probability':0.2,'bn_momentum':0.99, 'bn_epsilon':0.001})\n",
    "block_args.append({'kernel':3,'n_repeat':3,'in_channel':40, 'out_channel':80,'expand_ratio':6,'stride':2, 'se_ratio':1/4,\n",
    "           'skip_probability':0.2,'bn_momentum':0.99, 'bn_epsilon':0.001})\n",
    "block_args.append({'kernel':5,'n_repeat':3,'in_channel':80, 'out_channel':112,'expand_ratio':6,'stride':1, 'se_ratio':1/4,\n",
    "           'skip_probability':0.2,'bn_momentum':0.99, 'bn_epsilon':0.001})\n",
    "block_args.append({'kernel':5,'n_repeat':4,'in_channel':112, 'out_channel':192,'expand_ratio':6,'stride':2, 'se_ratio':1/4,\n",
    "           'skip_probability':0.2,'bn_momentum':0.99, 'bn_epsilon':0.001})\n",
    "block_args.append({'kernel':3,'n_repeat':1,'in_channel':192, 'out_channel':320,'expand_ratio':6,'stride':1, 'se_ratio':1/4,\n",
    "           'skip_probability':0.2,'bn_momentum':0.99, 'bn_epsilon':0.001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(20, 3, 224, 224)\n",
    "expand = EfficientNet(block_args)\n",
    "expand_output = expand(x)\n",
    "expand_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
